## 0. Introduction

### 0.1 General Introduction To Deep Learning

> Deep Learning is a class of machine learning methods that use neural networks to learn representations from raw data.

什么是 deep learning? 简单的说， deep learning 是利用深度神经网络学习数据的表示的一种机器学习方法。这里的“深度”指的是神经网络的层数，而“学习数据的表示”指的是神经网络的参数，也就是说，我们通过调整神经网络的参数来学习数据的表示。

> There're two kinds of model, one is the discriminative
> model from $X$ to $Y$ , the other is the generative model
> from $Y$ to $X$ .(Yi Wu)

更加数学化地，我们有一个目标函数 $f$ ,而我们希望用一个带参数的神经网络 $NN_\theta$ 去拟合 $f$ ，使得 $NN_\theta(x) \approx f(x)$ ,这就是深度学习想做的事情，而找到这个 $\theta$ 的过程就是 ~~炼丹~~ 训练(train)。

根据所学习的 $f$ 的不同，我们可以把任务分成两类，从而对应两类不同的模型：生成式模型(Generative Models)和判别式模型(Discriminative Models)。例如，当数据是手写数字的图片时，生成式模型的目标是给定一个数字，生成一张图片，而判别式模型的目标是给定一张图片，判断这张图片是什么数字。

这两者在数学上的本质区别实际上是 $f$ 的性质，判别式模型学习的 $f$ 是一个**映射** $f(x)=y$ ,也就是说给定一个 $x$ (一般称作data),我们就有唯一对应目标的 $y$ (一般称作label,或许你会说对于噪声图片 $x$ 似乎也没有我们想要对应的 $y$ ，但是这里的讨论中，把定义域先当成我们想要的图片(训练图片，测试图片...))，而生成式模型则是给定 $y$ ,希望输出一个 $x$ ,学习的是**映射的"反函数"** $f^{-1}(y)=x$ .(也许追求严谨的人到这里已经看不下去了，但别急，后面有详细的解释)

到这里，你可能会发现我们一直在回避一个定义上的问题，这个函数的定义域和值域究竟是什么？还是回到手写数字-标签的例子，对 $y$ 的值域 $Y$ 这是简单的，就是所有标签的集合，而对于 $x$ 的定义域，事实上，作为一个神经网络，它可以接受的 $x$ 自然是所有可能图片的集合，然而我们并不关心它在大多数噪声图片上的表现，而是只关心我们想要的真正的数字图片的识别效果，也就是说，加入我们把所有图片的集合设为 $\Omega$ ,那我们关心的只是 $\Omega$ 的一个小子集 $X_0$ ,代表所有手写数字的图片的集合。

对于判别式模型, 我们希望 $NN(x)\approx f(x)(x\in X_0$ ).

$X_0$ 究竟是什么呢?我们可以发现这和我们任务的定义有关，并没有数学上严格的说法。我们有什么？一般来说，我们有一个由一些满足 $f(x)=y$ 的 $(x,y)$ 构成的训练集 $P$ , 并且可以确定的是， $P$ 中的 $x$ 一定被 $X_0$ 包含，而我们凭借训练数据也知道不了更多了！所以，事实上，神经网络的训练只是关心 $NN(x) \approx f(x) (x\in P)$ , 而我们默认了 $X_0$ 有一些比较好的内在的性质，使得这可以让 $NN(x) \approx f(x) (x\in X_0)$ 也成立。这称为泛化能力(Generalization Ability)。

这个假设在数学上一般当然不成立，我们称满足 $NN(x) \approx f(x) (x\in P)$ 但是不满足 $NN(x) \approx f(x) (x\in X_0)$ 的现象为过拟合(Overfitting),而研究如何避免过拟合是判别式模型训练的重要内容,对于模型泛化能力的研究也是
深度学习理论研究的重点防线之一。你或许已经可以在上面我们问题的表述中想到一点如何避免过拟合的想法，我们将在下面的章节中详细讨论。

> “或许你overfit的模型，学到的正是某个平行世界中的特征”(Yao Seminar)

对于生成式模型，定义就更加模糊了。Generally speaking, 我们希望找到 $NN$ ,使得给定 $y$ ,我们可以生成一个 $NN(y) = x$ , 使得 $x \in X_0$ , 并且 $f(x) = y$ .

此时，我们的 $P$ 可以和之前一样，是满足 $f(x) = y$ 并且 $x \in X_0$ 的 $(x,y)$ , 但我们注意到这个时候没有标签的 $x \in X_0$ 也有了意义，因为我们可以通过它学到 $X_0$ 的信息！所以，根据训练数据是否有标签，我们可以把生成式模型的训练分成有监督(supervised learning),无监督(unsupervised learning)和半监督(semi-supervised learning)三种情况,分别对应数据全部有标签，全部无标签和部分有标签的情况。(显然，对于无监督情况，我们不能完成给定标签的生成)

当然，上面关于目标的定义显然可以找到很多cheat的方法，例如直接从训练集中找一张符合要求图片输出就可以达到目标，所以这里就涉及到评判模型好坏的标准了。

我们先说比较简单的评判判别式模型好坏的方法，一般来说是找 $X_0$ 的另一个子集 $P'$ ,称为测试集,然后用 $NN(x)$ 和 $f(x)$ 在 $P'$ 上的差距来衡量，
而有一些大家都认可的测试集，从而可以比较大家生成模型的好坏。

然而，对于生成式模型，就没那么简单了，首先 $X_0$ 没有明确数学定义，而
在判别式模型里我们只需要一个公认的 $X_0$ 的子集就行了，但在生成式模型里，我们似乎一定得搞明白 $X_0$ 究竟是什么！于是，这导致生成式模型到现在也没有一个universal的标准，而对于不同的生成式模型，我们也会有不同的评判标准，这在后面会详细讨论。但回到我们关于 $X_0$ 的定义，不就是“手写数字”的集合的主观定义嘛！所以有一个“耍赖”的评判标准——直接主观判断！这也是为什么许多生成式模型的论文里，往往会放很多生成的图片的原因，这也确实在某种方面上更加有说服力。

### 0.2 Training

深度学习发展至今，对于给定的网络结构，如何训练网络已经有了很多成熟的方法，其中的核心就是优化理论中的重要算法:梯度下降。

于是，模型的训练现在以及变成了一个程序化的过程:

- 1.定义模型结构
- 2.定义一个损失函数，表示模型的好坏
- 3.定义一个基于梯度下降的优化算法，使得损失函数最小化
- 4.根据算法优化损失函数，得到最终模型

所以，对于任何一个任务，我们就分成了四个步骤，而这四个步骤中的每一步都非常重要，直接关系到最终生成的结果。我们之后对于模型的介绍也基本会按照这个框架来进行。对于第三步，由于它和模型无关，所以我们会在下面先做讨论，对之后的所有模型，方法都是类似的。

### 0.3 Gradient Descent

#### 0.3.1 GD

当然，最简单的办法就是直接用梯度下降，也就是说，我们直接计算损失函数对于参数的梯度，然后按照梯度的方向更新参数。这个方法的优点是简单直接，但对于大多数情况来说，根本不现实，大部分训练集的规模都是非常大的，而计算梯度的时间复杂度也不低。

#### 0.3.2 SGD

于是，我们引入了SGD(Stochastic Gradient Descent),也就是说，我们不是计算整个训练集的梯度，而是每次只取数据集的一部分，称为一个batch，计算这个batch的梯度，然后更新参数。这样做可以显著减少计算量，这也是深度学习中常见的优化算法。(事实上，人们后来发现，SGD因为内在的随机性，还可以有效减轻过拟合问题)

实际应用中，为方便起见，一般都是直接把整个测试集分成若干个batch，然后每次取一个batch进行训练，对所有batch训练完一遍称为一个epoch，然后重复若干个epoch直到收敛。**之后的所有优化算法都是基于SGD的改进，核心思想都是通过减小震荡，加快收敛,具体的数学表达式可能比较复杂或者奇怪，而数学上的严格证明也大多和实际应用有一定的差距，所以我们在这里只做简单的介绍。~~不想看可以直接跳到下一节~~**

SGD的数学表达式可以写成这样:

$$
\theta_{t+1}=\theta_t-\eta \nabla E_{x \sim B}[L(\theta_t, x)]
$$

,
其中

$B$ 是一个batch, $\eta$ 是学习率， $L$ 是损失函数。

#### 0.3.3 Momentum

然而，SGD有一个问题，就是在到达最优点的时候，由于梯度的方向不断变化，可能会导致震荡，于是，我们引入了Momentum,也就是说，我们不仅仅考虑当前的梯度，还考虑之前的梯度，这样可以减小震荡，加快收敛。

Momentum的数学表达式可以写成这样:

$$
v_{t+1}=\gamma v_t+\eta \nabla E_{x \sim B}[L(\theta_t, x)]
$$

$$
\theta_{t+1}=\theta_t-v_{t+1}
$$

其中 $\gamma$ 是一个超参数，一般取0.9左右。(超参数指的是不通过训练得到的参数，而是需要人为设定的参数，区别于神经网络的参数)

#### 0.3.4 Adam(Adaptive Moment Estimation)

Adam是一种结合了SGD和Momentum的优化算法，它的优点是可以自适应地调整学习率，从而可以更好地适应不同的数据集。

Adam的数学表达式可以写成这样:

$$
m_{t+1}=\beta_1 m_t+(1-\beta_1)\nabla E_{x \sim B}[L(\theta_t, x)]
$$

$$
v_{t+1}=\beta_2 v_t+(1-\beta_2)(\nabla E_{x \sim B}[L(\theta_t, x)])^2
$$

$$
\hat{m}_{t+1}=\frac{m_{t+1}}{1-\beta_1^{t+1}}
$$

$$
\hat{v}_{t+1}=\frac{v_{t+1}}{1-\beta_2^{t+1}}
$$

$$
\theta_{t+1}=\theta_t-\eta \frac{\hat{m}_{t+1}}{\sqrt{{\hat{v}_{t+1}}+\epsilon}}
$$

其中 $\beta_1,\beta_2$ 是超参数， $\epsilon$ 是一个很小的数，一般取 $10^{-8}$ 左右。
